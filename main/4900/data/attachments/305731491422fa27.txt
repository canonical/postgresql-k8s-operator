[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:476 starting continuous writes to the database
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:479 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 5, 'testing.postgresql-k8s-1': 6}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 10, 'testing.postgresql-k8s-1': 10}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:483 scaling out the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 4 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Primary (degraded)
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [idle] maintenance: installing charm software
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Primary (degraded)
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [idle] maintenance: installing charm software
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [executing] active: Primary
  postgresql-k8s/1 [executing] active: 
  postgresql-k8s/2 [executing] active: 
  postgresql-k8s/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/3 [executing] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:487 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 335, 'testing.postgresql-k8s-1': 335, 'testing.postgresql-k8s-2': 335, 'testing-other.postgresql-k8s-1': 335}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 339, 'testing.postgresql-k8s-1': 339, 'testing.postgresql-k8s-2': 339, 'testing-other.postgresql-k8s-1': 339}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:490 scaling out the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 4 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [executing] active: 
  postgresql-k8s/1 [executing] active: Standby (degraded)
  postgresql-k8s/2 [executing] active: 
  postgresql-k8s/3 [executing] maintenance: installing charm software
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: Standby (degraded)
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [idle] maintenance: installing charm software
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: Standby
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/3 [executing] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/3 [executing] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:496 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 678, 'testing.postgresql-k8s-1': 678, 'testing.postgresql-k8s-2': 678, 'testing-other.postgresql-k8s-1': 678}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 682, 'testing.postgresql-k8s-1': 682, 'testing.postgresql-k8s-2': 682, 'testing-other.postgresql-k8s-1': 682}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:499 scaling in the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Primary
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:502 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 858, 'testing.postgresql-k8s-1': 858, 'testing-other.postgresql-k8s-1': 858}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 862, 'testing.postgresql-k8s-1': 862, 'testing-other.postgresql-k8s-1': 862}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:505 scaling in the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: Standby
  postgresql-k8s/2 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:510 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 997, 'testing.postgresql-k8s-1': 997, 'testing-other.postgresql-k8s-1': 997}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 1003, 'testing.postgresql-k8s-1': 1003, 'testing-other.postgresql-k8s-1': 1003}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:515 checking whether no writes were lost
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.90:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:83 Destroying second model
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller          Cloud/Region        Version  SLA          Timestamp
testing  concierge-microk8s  microk8s/localhost  3.6.12   unsupported  01:58:26Z

App                  Version  Status  Scale  Charm                Channel      Rev  Address         Exposed  Message
postgresql-k8s       14.19    active      3  postgresql-k8s                      0  10.152.183.254  no       Primary
postgresql-test-app           active      1  postgresql-test-app  latest/edge  420  10.152.183.198  no       received database credentials of the first database

Unit                    Workload  Agent      Address       Ports  Message
postgresql-k8s/0        active    executing  10.1.243.140         Primary
postgresql-k8s/1        active    executing  10.1.243.142         
postgresql-k8s/2*       active    executing  10.1.243.151         
postgresql-test-app/0*  active    idle       10.1.243.150         received database credentials of the first database

Offer              Application     Charm           Rev  Connected  Endpoint           Interface         Role
replication        postgresql-k8s  postgresql-k8s  0    0/0        replication        postgresql_async  requirer
replication-offer  postgresql-k8s  postgresql-k8s  0    1/1        replication-offer  postgresql_async  provider

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

unit-postgresql-k8s-2: 01:46:46 ERROR unit.postgresql-k8s/2.juju-log failed to patch k8s Endpoints patroni-postgresql-k8s
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 279, in raise_for_status
    resp.raise_for_status()
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '409 Conflict' for url 'https://10.152.183.1/api/v1/namespaces/testing/endpoints/patroni-postgresql-k8s?force=true&fieldManager=postgresql-k8s'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 1468, in _on_stop
    client.apply(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/client.py", line 767, in apply
    return self.patch(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/client.py", line 490, in patch
    return self._client.request(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 359, in request
    return self.handle_response(method, resp, br)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 293, in handle_response
    self.raise_for_status(resp)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 281, in raise_for_status
    raise transform_exception(e) from e
lightkube.core.exceptions.ApiError: Operation cannot be fulfilled on endpoints "patroni-postgresql-k8s": the object has been modified; please apply your changes to the latest version and try again
unit-postgresql-k8s-2: 01:46:46 ERROR unit.postgresql-k8s/2.juju-log failed to patch k8s Endpoints patroni-postgresql-k8s-sync
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 279, in raise_for_status
    resp.raise_for_status()
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '409 Conflict' for url 'https://10.152.183.1/api/v1/namespaces/testing/endpoints/patroni-postgresql-k8s-sync?force=true&fieldManager=postgresql-k8s'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 1468, in _on_stop
    client.apply(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/client.py", line 767, in apply
    return self.patch(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/client.py", line 490, in patch
    return self._client.request(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 359, in request
    return self.handle_response(method, resp, br)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 293, in handle_response
    self.raise_for_status(resp)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 281, in raise_for_status
    raise transform_exception(e) from e
lightkube.core.exceptions.ApiError: Operation cannot be fulfilled on endpoints "patroni-postgresql-k8s-sync": the object has been modified; please apply your changes to the latest version and try again
unit-postgresql-k8s-2: 01:46:46 ERROR unit.postgresql-k8s/2.juju-log failed to patch k8s Endpoints postgresql-k8s-primary
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 279, in raise_for_status
    resp.raise_for_status()
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '409 Conflict' for url 'https://10.152.183.1/api/v1/namespaces/testing/endpoints/postgresql-k8s-primary?force=true&fieldManager=postgresql-k8s'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 1468, in _on_stop
    client.apply(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/client.py", line 767, in apply
    return self.patch(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/client.py", line 490, in patch
    return self._client.request(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 359, in request
    return self.handle_response(method, resp, br)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 293, in handle_response
    self.raise_for_status(resp)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 281, in raise_for_status
    raise transform_exception(e) from e
lightkube.core.exceptions.ApiError: Operation cannot be fulfilled on endpoints "postgresql-k8s-primary": the object has been modified; please apply your changes to the latest version and try again
unit-postgresql-k8s-2: 01:46:47 ERROR unit.postgresql-k8s/2.juju-log failed to patch k8s Endpoints postgresql-k8s-replicas
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 279, in raise_for_status
    resp.raise_for_status()
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '409 Conflict' for url 'https://10.152.183.1/api/v1/namespaces/testing/endpoints/postgresql-k8s-replicas?force=true&fieldManager=postgresql-k8s'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 1468, in _on_stop
    client.apply(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/client.py", line 767, in apply
    return self.patch(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/client.py", line 490, in patch
    return self._client.request(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 359, in request
    return self.handle_response(method, resp, br)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 293, in handle_response
    self.raise_for_status(resp)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/lightkube/core/generic_client.py", line 281, in raise_for_status
    raise transform_exception(e) from e
lightkube.core.exceptions.ApiError: Operation cannot be fulfilled on endpoints "postgresql-k8s-replicas": the object has been modified; please apply your changes to the latest version and try again
unit-postgresql-k8s-2: 01:47:06 ERROR unit.postgresql-k8s/2.juju-log Cluster upgrade failed, ensure pre-upgrade checks are ran first.
unit-postgresql-k8s-1: 01:49:58 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-0: 01:50:00 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-test-app-0: 01:50:05 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-2: 01:52:02 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-3: 01:52:05 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-0: 01:54:04 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-1: 01:54:04 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
controller-0: 01:55:36 ERROR juju.worker.caasapplicationprovisioner.runner exited "postgresql-k8s": updating filesystem information for postgresql-k8s: cannot set info for filesystem attachment 3:postgresql-k8s/3: state changing too quickly; try again soon
controller-0: 01:56:28 ERROR juju.worker.caasapplicationprovisioner.runner exited "postgresql-k8s": finding filesystem info for postgresql-k8s-pgdata-7c6f604f: unable to get persistent volume claim: k8s: persistentvolumeclaims "postgresql-k8s-pgdata-7c6f604f-postgresql-k8s-3" not found

[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...