[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:336 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:342 confirming that the primary is not isolated from the cluster
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:346 Cutting network for postgresql-k8s/2
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:350 checking whether the connectivity to the database is not working
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:355 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 305, 'testing.postgresql-k8s-1': 305}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 309, 'testing.postgresql-k8s-1': 309}
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:358 checking whether a new primary was elected
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:367 confirming that the former primary is isolated from the cluster
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:371 Restoring network for postgresql-k8s/2
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:375 waiting for the database service to restart on postgresql-k8s/2
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:379 checking whether the connectivity to the database is working
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.14:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller          Cloud/Region        Version  SLA          Timestamp
testing  concierge-microk8s  microk8s/localhost  3.6.14   unsupported  00:43:35Z

App                  Version  Status  Scale  Charm                Channel      Rev  Address         Exposed  Message
postgresql-k8s       14.20    active      3  postgresql-k8s                      0  10.152.183.156  no       
postgresql-test-app           active      1  postgresql-test-app  latest/edge  446  10.152.183.176  no       received database credentials of the first database

Unit                    Workload  Agent  Address      Ports  Message
postgresql-k8s/0*       active    idle   10.1.114.76         Primary
postgresql-k8s/1        active    idle   10.1.114.77         
postgresql-k8s/2        active    idle   10.1.114.78         
postgresql-test-app/0*  active    idle   10.1.114.75         received database credentials of the first database

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

unit-postgresql-k8s-1: 00:11:22 ERROR unit.postgresql-k8s/1.juju-log database-peers:0: Failed to list PostgreSQL database users: connection to server at "postgresql-k8s-1.postgresql-k8s-endpoints.testing.svc.cluster.local" (10.1.114.77), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

unit-postgresql-k8s-1: 00:30:33 ERROR unit.postgresql-k8s/1.juju-log Failed to restart patroni
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/src/charm.py", line 1533, in _on_update_status
    container.restart(self.postgresql_service)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/lib/python3.10/site-packages/ops/model.py", line 2613, in restart
    self._pebble.restart_services(service_names)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/lib/python3.10/site-packages/ops/pebble.py", line 2401, in restart_services
    return self._services_action('restart', services, timeout, delay)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/lib/python3.10/site-packages/ops/pebble.py", line 2428, in _services_action
    raise ChangeError(change.err, change)
ops.pebble.ChangeError: cannot perform the following tasks:
- Start service "postgresql" (cannot start service while terminating)
----- Logs from task 0 -----
2026-03-01T00:30:33Z INFO Service "postgresql" already stopping.
----- Logs from task 1 -----
2026-03-01T00:30:33Z ERROR cannot start service while terminating
-----
unit-postgresql-k8s-2: 00:31:06 ERROR unit.postgresql-k8s/2.juju-log Failed to restart patroni
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 1533, in _on_update_status
    container.restart(self.postgresql_service)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/model.py", line 2613, in restart
    self._pebble.restart_services(service_names)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/pebble.py", line 2401, in restart_services
    return self._services_action('restart', services, timeout, delay)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/pebble.py", line 2428, in _services_action
    raise ChangeError(change.err, change)
ops.pebble.ChangeError: cannot perform the following tasks:
- Start service "postgresql" (cannot start service while terminating)
----- Logs from task 0 -----
2026-03-01T00:31:06Z INFO Service "postgresql" already stopping.
----- Logs from task 1 -----
2026-03-01T00:31:06Z ERROR cannot start service while terminating
-----
unit-postgresql-k8s-2: 00:42:21 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b50bca] "unit-postgresql-k8s-2" cannot open api: cannot resolve "controller-service.controller-concierge-microk8s.svc.cluster.local": lookup controller-service.controller-concierge-microk8s.svc.cluster.local: i/o timeout
unit-postgresql-k8s-2: 00:42:28 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b50bca] "unit-postgresql-k8s-2" cannot open api: cannot resolve "controller-service.controller-concierge-microk8s.svc.cluster.local": lookup controller-service.controller-concierge-microk8s.svc.cluster.local: i/o timeout
unit-postgresql-k8s-2: 00:42:35 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b50bca] "unit-postgresql-k8s-2" cannot open api: cannot resolve "controller-service.controller-concierge-microk8s.svc.cluster.local": lookup controller-service.controller-concierge-microk8s.svc.cluster.local: i/o timeout
unit-postgresql-k8s-2: 00:43:04 ERROR unit.postgresql-k8s/2.juju-log Failed to list PostgreSQL database users: connection to server at "postgresql-k8s-2.postgresql-k8s-endpoints.testing.svc.cluster.local" (10.1.114.78), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...