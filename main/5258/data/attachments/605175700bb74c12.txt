[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:336 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:342 confirming that the primary is not isolated from the cluster
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:346 Cutting network for postgresql-k8s/2
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:350 checking whether the connectivity to the database is not working
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:355 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 300, 'testing.postgresql-k8s-1': 300}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 304, 'testing.postgresql-k8s-1': 304}
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:358 checking whether a new primary was elected
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:367 confirming that the former primary is isolated from the cluster
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:371 Restoring network for postgresql-k8s/2
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:375 waiting for the database service to restart on postgresql-k8s/2
[32mINFO    [0m integration.ha_tests.test_self_healing_1:test_self_healing_1.py:379 checking whether the connectivity to the database is working
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.247:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller          Cloud/Region        Version  SLA          Timestamp
testing  concierge-microk8s  microk8s/localhost  3.6.14   unsupported  00:45:57Z

App                  Version  Status  Scale  Charm                Channel      Rev  Address         Exposed  Message
postgresql-k8s       14.20    active      3  postgresql-k8s                      0  10.152.183.189  no       
postgresql-test-app           active      1  postgresql-test-app  latest/edge  436  10.152.183.185  no       received database credentials of the first database

Unit                    Workload  Agent  Address      Ports  Message
postgresql-k8s/0*       active    idle   10.1.119.11         
postgresql-k8s/1        active    idle   10.1.119.13         Primary
postgresql-k8s/2        active    idle   10.1.119.12         
postgresql-test-app/0*  active    idle   10.1.119.14         received database credentials of the first database

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

unit-postgresql-k8s-0: 00:11:41 ERROR unit.postgresql-k8s/0.juju-log Failed to list PostgreSQL database access groups: connection to server at "postgresql-k8s-primary.testing.svc.cluster.local" (10.152.183.70), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

unit-postgresql-k8s-0: 00:11:41 ERROR unit.postgresql-k8s/0.juju-log Uncaught exception while in charm code:
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 652, in list_access_groups
    with self._connect_to_database(
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 184, in _connect_to_database
    connection = psycopg2.connect(
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgresql-k8s-primary.testing.svc.cluster.local" (10.152.183.70), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/src/charm.py", line 2785, in <module>
    main(PostgresqlOperatorCharm, use_juju_for_storage=True)
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/ops/__init__.py", line 360, in __call__
    return _main.main(charm_class=charm_class, use_juju_for_storage=use_juju_for_storage)
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/ops/_main.py", line 507, in main
    manager.run()
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/ops/_main.py", line 491, in run
    self._emit()
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/ops/_main.py", line 426, in _emit
    self._emit_charm_event(self.dispatcher.event_name)
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/ops/_main.py", line 470, in _emit_charm_event
    event_to_emit.emit(*args, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/ops/framework.py", line 337, in emit
    framework._emit(event)
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/ops/framework.py", line 910, in _emit
    self._reemit(event_path)
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/venv/lib/python3.10/site-packages/ops/framework.py", line 1028, in _reemit
    custom_handler(event)
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/src/charm.py", line 1028, in _on_postgresql_pebble_ready
    if self.unit.is_leader() and not self._initialize_cluster(event):
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/src/charm.py", line 1120, in _initialize_cluster
    access_groups = self.postgresql.list_access_groups()
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 946, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-postgresql-k8s-0/charm/lib/charms/postgresql_k8s/v0/postgresql.py", line 662, in list_access_groups
    raise PostgreSQLListGroupsError() from e
charms.postgresql_k8s.v0.postgresql.PostgreSQLListGroupsError
unit-postgresql-k8s-0: 00:11:42 ERROR juju.worker.uniter.operation hook "postgresql-pebble-ready" (via hook dispatching script: dispatch) failed: exit status 1
unit-postgresql-k8s-0: 00:11:42 ERROR juju.worker.uniter pebble poll failed for container "postgresql": failed to send pebble-ready event: hook failed
unit-postgresql-k8s-2: 00:44:50 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [dc2a0a] "unit-postgresql-k8s-2" cannot open api: cannot resolve "controller-service.controller-concierge-microk8s.svc.cluster.local": lookup controller-service.controller-concierge-microk8s.svc.cluster.local: i/o timeout
unit-postgresql-k8s-2: 00:44:56 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [dc2a0a] "unit-postgresql-k8s-2" cannot open api: cannot resolve "controller-service.controller-concierge-microk8s.svc.cluster.local": lookup controller-service.controller-concierge-microk8s.svc.cluster.local: i/o timeout
unit-postgresql-k8s-2: 00:45:31 ERROR unit.postgresql-k8s/2.juju-log Failed to list PostgreSQL database users: connection to server at "postgresql-k8s-2.postgresql-k8s-endpoints.testing.svc.cluster.local" (10.1.119.12), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?


[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...