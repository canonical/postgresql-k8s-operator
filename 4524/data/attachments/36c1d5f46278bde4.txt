[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:476 starting continuous writes to the database
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:479 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 5, 'testing.postgresql-k8s-1': 6, 'testing.postgresql-k8s-2': 6}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 10, 'testing.postgresql-k8s-1': 10, 'testing.postgresql-k8s-2': 10}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:483 scaling out the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 4 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [executing] active: Primary (degraded)
  postgresql-k8s/3 [executing] maintenance: installing charm software
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] maintenance: reconfiguring cluster
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: Primary (degraded)
  postgresql-k8s/3 [executing] waiting: awaiting for cluster to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [executing] waiting: awaiting for member to start
  postgresql-k8s/2 [executing] active: Primary (degraded)
  postgresql-k8s/3 [executing] waiting: awaiting for cluster to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] waiting: awaiting for member to start
  postgresql-k8s/2 [idle] active: Primary
  postgresql-k8s/3 [idle] waiting: awaiting for cluster to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: Primary
  postgresql-k8s/3 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] waiting: awaiting for member to start
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: Primary
  postgresql-k8s/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: Primary
  postgresql-k8s/3 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/3 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/3 [idle] active: 
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:487 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-3 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 530, 'testing.postgresql-k8s-1': 530, 'testing.postgresql-k8s-2': 530, 'testing.postgresql-k8s-3': 530, 'testing-other.postgresql-k8s-0': 531}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-3 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 535, 'testing.postgresql-k8s-1': 535, 'testing.postgresql-k8s-2': 535, 'testing.postgresql-k8s-3': 535, 'testing-other.postgresql-k8s-0': 535}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:490 scaling out the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 4 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Standby (degraded)
  postgresql-k8s/1 [idle] maintenance: reconfiguring cluster
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [idle] maintenance: installing charm software
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Standby (degraded)
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [executing] active: 
  postgresql-k8s/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Standby
  postgresql-k8s/1 [idle] maintenance: reinitialising replica
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [idle] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Standby
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:496 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-3 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 779, 'testing.postgresql-k8s-1': 779, 'testing.postgresql-k8s-2': 779, 'testing.postgresql-k8s-3': 779, 'testing-other.postgresql-k8s-0': 779}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-3 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 785, 'testing.postgresql-k8s-1': 785, 'testing.postgresql-k8s-2': 785, 'testing.postgresql-k8s-3': 785, 'testing-other.postgresql-k8s-0': 785}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:499 scaling in the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: Primary
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:502 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 967, 'testing.postgresql-k8s-1': 967, 'testing.postgresql-k8s-2': 967, 'testing-other.postgresql-k8s-0': 967}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 972, 'testing.postgresql-k8s-1': 972, 'testing.postgresql-k8s-2': 972, 'testing-other.postgresql-k8s-0': 972}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:505 scaling in the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:510 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 1131, 'testing.postgresql-k8s-1': 1131, 'testing.postgresql-k8s-2': 1131, 'testing-other.postgresql-k8s-0': 1131}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 1135, 'testing.postgresql-k8s-1': 1135, 'testing.postgresql-k8s-2': 1136, 'testing-other.postgresql-k8s-0': 1136}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:515 checking whether no writes were lost
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.89:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:83 Destroying second model
[32mINFO    [0m pytest_operator.plugin:plugin.py:951 Model status:

Model    Controller          Cloud/Region        Version  SLA          Timestamp
testing  concierge-microk8s  microk8s/localhost  3.6.9    unsupported  02:11:07Z

App                  Version  Status  Scale  Charm                Channel      Rev  Address         Exposed  Message
postgresql-k8s       14.18    active      3  postgresql-k8s                      0  10.152.183.157  no       Primary
postgresql-test-app           active      1  postgresql-test-app  latest/edge  406  10.152.183.241  no       received database credentials of the first database

Unit                    Workload  Agent      Address      Ports  Message
postgresql-k8s/0*       active    executing  10.1.242.87         
postgresql-k8s/1        active    executing  10.1.242.77         
postgresql-k8s/2        active    executing  10.1.242.78         Primary
postgresql-test-app/0*  active    idle       10.1.242.85         received database credentials of the first database

Offer              Application     Charm           Rev  Connected  Endpoint           Interface         Role
replication        postgresql-k8s  postgresql-k8s  0    0/0        replication        postgresql_async  requirer
replication-offer  postgresql-k8s  postgresql-k8s  0    1/1        replication-offer  postgresql_async  provider

[32mINFO    [0m pytest_operator.plugin:plugin.py:957 Juju error logs:

unit-postgresql-k8s-2: 01:32:37 ERROR unit.postgresql-k8s/2.juju-log Uncaught exception while in charm code:
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/model.py", line 3637, in _run
    result = subprocess.run(args, **kwargs)  # type: ignore
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command '('/var/lib/juju/tools/unit-postgresql-k8s-2/secret-get', '--label', 'database-peers.postgresql-k8s.app', '--format=json')' returned non-zero exit status 1.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 2561, in <module>
    main(PostgresqlOperatorCharm, use_juju_for_storage=True)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/__init__.py", line 356, in __call__
    return _main.main(charm_class=charm_class, use_juju_for_storage=use_juju_for_storage)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/_main.py", line 502, in main
    manager.run()
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/_main.py", line 486, in run
    self._emit()
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/_main.py", line 421, in _emit
    self._emit_charm_event(self.dispatcher.event_name)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/_main.py", line 465, in _emit_charm_event
    event_to_emit.emit(*args, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/framework.py", line 351, in emit
    framework._emit(event)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/framework.py", line 924, in _emit
    self._reemit(event_path)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/framework.py", line 1030, in _reemit
    custom_handler(event)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1146, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 1002, in _on_postgresql_pebble_ready
    self.unit.set_workload_version(self._patroni.rock_postgresql_version)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 1682, in _patroni
    self.get_secret(APP_SCOPE, PATRONI_PASSWORD_KEY),
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/tempo_coordinator_k8s/v0/charm_tracing.py", line 1146, in wrapped_function
    return callable(*args, **kwargs)  # type: ignore
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/src/charm.py", line 381, in get_secret
    if result := self.peer_relation_data(scope).fetch_my_relation_field(peers.id, key):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 1732, in fetch_my_relation_field
    if relation_data := self.fetch_my_relation_data([relation_id], [field], relation_name):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 1721, in fetch_my_relation_data
    data[relation.id] = self._fetch_my_specific_relation_data(relation, fields)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 656, in wrapper
    return f(self, *args, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 2613, in _fetch_my_specific_relation_data
    self.component, self.local_secret_fields, relation, fields
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 2235, in local_secret_fields
    self.static_secret_fields if self.static_secret_fields else self.current_secret_fields
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 2259, in current_secret_fields
    if content := self._get_group_secret_contents(relation, group):
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 2600, in _get_group_secret_contents
    result = super()._get_group_secret_contents(relation, group, secret_fields)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 1452, in _get_group_secret_contents
    if (secret := self._get_relation_secret(relation.id, group)) and (
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 628, in wrapper
    return f(self, *args, **kwargs)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 2587, in _get_relation_secret
    return self.secrets.get(
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 934, in get
    if secret.meta:
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/lib/charms/data_platform_libs/v0/data_interfaces.py", line 764, in meta
    self._secret_meta = self._model.get_secret(label=self.label)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/model.py", line 325, in get_secret
    content = self._backend.secret_get(id=id, label=label)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/model.py", line 4023, in secret_get
    result = self._run('secret-get', *args, return_output=True, use_json=True)
  File "/var/lib/juju/agents/unit-postgresql-k8s-2/charm/venv/lib/python3.10/site-packages/ops/model.py", line 3639, in _run
    raise ModelError(e.stderr) from e
ops.model.ModelError: ERROR permission denied

unit-postgresql-k8s-2: 01:32:37 ERROR juju.worker.uniter.operation hook "postgresql-pebble-ready" (via hook dispatching script: dispatch) failed: exit status 1
unit-postgresql-k8s-2: 01:32:37 ERROR juju.worker.uniter pebble poll failed for container "postgresql": failed to send pebble-ready event: hook failed
unit-postgresql-k8s-2: 01:36:01 ERROR unit.postgresql-k8s/2.juju-log pgdata folder not found in /var/lib/postgresql/data/pgdata
unit-postgresql-k8s-0: 01:57:03 ERROR unit.postgresql-k8s/0.juju-log Cluster upgrade failed, ensure pre-upgrade checks are ran first.
unit-postgresql-k8s-1: 01:59:50 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-2: 01:59:50 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-test-app-0: 01:59:59 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-2: 02:03:24 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-1: 02:03:25 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-0: 02:06:21 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-3: 02:07:34 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-test-app-0: 02:07:41 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-2: 02:10:13 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-1: 02:10:13 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent

[32mINFO    [0m pytest_operator.plugin:plugin.py:1039 Forgetting model main...