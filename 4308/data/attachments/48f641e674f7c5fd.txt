[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:482 starting continuous writes to the database
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:485 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 3, 'testing.postgresql-k8s-2': -1}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 3, 'testing.postgresql-k8s-2': -1}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 8, 'testing.postgresql-k8s-2': 8}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:489 scaling out the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 4 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Primary (degraded)
  postgresql-k8s/1 [executing] active: 
  postgresql-k8s/2 [executing] active: 
  postgresql-k8s/3 [executing] maintenance: installing charm software
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [executing] active: Primary (degraded)
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [executing] waiting: awaiting for cluster to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Primary (degraded)
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: 
  postgresql-k8s/3 [executing] waiting: awaiting for cluster to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Primary
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] waiting: awaiting for member to start
  postgresql-k8s/3 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:493 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 272, 'testing.postgresql-k8s-1': 272, 'testing.postgresql-k8s-2': 272, 'testing-other.postgresql-k8s-2': 272}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 282, 'testing.postgresql-k8s-1': 282, 'testing.postgresql-k8s-2': 282, 'testing-other.postgresql-k8s-2': 282}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:496 scaling out the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 4 units, current : 3)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [executing] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: Standby (degraded)
  postgresql-k8s/3 [executing] maintenance: installing charm software
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: Standby (degraded)
  postgresql-k8s/3 [executing] waiting: awaiting for member to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [executing] maintenance: reinitialising replica
  postgresql-k8s/2 [idle] active: Standby (degraded)
  postgresql-k8s/3 [idle] waiting: awaiting for cluster to start
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: Standby
  postgresql-k8s/3 [idle] waiting: awaiting for member to start
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:502 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 546, 'testing.postgresql-k8s-1': 547, 'testing.postgresql-k8s-2': 547, 'testing-other.postgresql-k8s-2': 547}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 553, 'testing.postgresql-k8s-1': 553, 'testing.postgresql-k8s-2': 553, 'testing-other.postgresql-k8s-2': 553}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:505 scaling in the first cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s/0 [idle] active: Primary
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:508 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 718, 'testing.postgresql-k8s-2': 718, 'testing-other.postgresql-k8s-2': 718}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 722, 'testing.postgresql-k8s-2': 722, 'testing-other.postgresql-k8s-2': 722}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:511 scaling in the second cluster
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m juju.model:__init__.py:3254 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 4)
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:516 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:242 Initial writes {'testing.postgresql-k8s-0': 886, 'testing.postgresql-k8s-2': 886, 'testing-other.postgresql-k8s-2': 886}
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.helpers:helpers.py:248 Retry writes {'testing.postgresql-k8s-0': 892, 'testing.postgresql-k8s-2': 892, 'testing-other.postgresql-k8s-2': 892}
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:521 checking whether no writes were lost
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1025 HTTP Request: GET https://10.1.0.116:16443/api/v1/namespaces/testing-other/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.test_async_replication:test_async_replication.py:83 Destroying second model
[32mINFO    [0m pytest_operator.plugin:plugin.py:937 Model status:

Model    Controller          Cloud/Region        Version  SLA          Timestamp
testing  concierge-microk8s  microk8s/localhost  3.6.8    unsupported  02:11:42Z

App                  Version  Status  Scale  Charm                Channel      Rev  Address        Exposed  Message
postgresql-k8s       14.18    active      3  postgresql-k8s                      0  10.152.183.39  no       Primary
postgresql-test-app           active      1  postgresql-test-app  latest/edge  392  10.152.183.45  no       received database credentials of the first database

Unit                    Workload  Agent      Address     Ports  Message
postgresql-k8s/0        active    executing  10.1.98.12         Primary
postgresql-k8s/1*       active    executing  10.1.98.23         
postgresql-k8s/2        active    executing  10.1.98.14         
postgresql-test-app/0*  active    idle       10.1.98.21         received database credentials of the first database

Offer              Application     Charm           Rev  Connected  Endpoint           Interface         Role
replication        postgresql-k8s  postgresql-k8s  0    0/0        replication        postgresql_async  requirer
replication-offer  postgresql-k8s  postgresql-k8s  0    1/1        replication-offer  postgresql_async  provider

[32mINFO    [0m pytest_operator.plugin:plugin.py:943 Juju error logs:

unit-postgresql-k8s-0: 01:35:06 ERROR unit.postgresql-k8s/0.juju-log pgdata folder not found in /var/lib/postgresql/data/pgdata
unit-postgresql-k8s-2: 01:35:06 ERROR unit.postgresql-k8s/2.juju-log pgdata folder not found in /var/lib/postgresql/data/pgdata
unit-postgresql-k8s-1: 01:49:41 ERROR juju.worker.dependency "uniter" manifold worker returned unexpected error: relation scope id "019d6dbd-a7fc-4c64-869b-577992650a3f:r#5#remote-9f7e0e2292aa49c7816facf9827a4423": settings 019d6dbd-a7fc-4c64-869b-577992650a3f:r#5#remote-9f7e0e2292aa49c7816facf9827a4423 not found (not found)
unit-postgresql-k8s-1: 01:59:24 ERROR unit.postgresql-k8s/1.juju-log Cluster upgrade failed, ensure pre-upgrade checks are ran first.
unit-postgresql-test-app-0: 02:02:14 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-0: 02:02:18 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-2: 02:02:21 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent
unit-postgresql-k8s-1: 02:08:57 ERROR juju.worker.dependency "log-sender" manifold worker returned unexpected error: sending log message: websocket: close 1005 (no status): websocket: close sent

[32mINFO    [0m pytest_operator.plugin:plugin.py:1025 Forgetting model main...