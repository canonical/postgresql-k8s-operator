[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:326 checking whether the connectivity to the database is working
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:332 confirming that the primary is not isolated from the cluster
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:336 Cutting network for postgresql-k8s/0
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:340 checking whether the connectivity to the database is not working
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:345 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:348 checking whether a new primary was elected
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:357 confirming that the former primary is isolated from the cluster
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:361 Restoring network for postgresql-k8s/0
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:365 waiting for the database service to restart on postgresql-k8s/0
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:369 checking whether the connectivity to the database is working
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1038 HTTP Request: GET https://10.1.0.170:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m pytest_operator.plugin:plugin.py:903 Model status:

Model  Controller          Cloud/Region        Version  SLA          Timestamp
test   microk8s-localhost  microk8s/localhost  3.4.6    unsupported  02:02:51Z

App                  Version  Status   Scale  Charm                Channel      Rev  Address         Exposed  Message
postgresql-k8s       14.13    waiting      3  postgresql-k8s                      0  10.152.183.70   no       installing agent
postgresql-test-app           active       1  postgresql-test-app  latest/edge  252  10.152.183.160  no       received database credentials of the first database

Unit                    Workload     Agent  Address      Ports  Message
postgresql-k8s/0        active       idle   10.1.77.203         
postgresql-k8s/1        maintenance  idle   10.1.77.205         Database service inactive, restarting
postgresql-k8s/2*       active       idle   10.1.77.204         
postgresql-test-app/0*  active       idle   10.1.77.206         received database credentials of the first database

[32mINFO    [0m pytest_operator.plugin:plugin.py:909 Juju error logs:

unit-postgresql-k8s-1: 01:45:23 ERROR unit.postgresql-k8s/1.juju-log Failed to restart patroni
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/./src/charm.py", line 1418, in _on_update_status
    container.restart(self._postgresql_service)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/ops/model.py", line 2399, in restart
    self._pebble.restart_services(service_names)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/ops/pebble.py", line 2219, in restart_services
    return self._services_action('restart', services, timeout, delay)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/ops/pebble.py", line 2244, in _services_action
    raise ChangeError(change.err, change)
ops.pebble.ChangeError: cannot perform the following tasks:
- Start service "postgresql" (cannot start service while terminating)
----- Logs from task 0 -----
2024-10-03T01:45:23Z INFO Service "postgresql" already stopping.
----- Logs from task 1 -----
2024-10-03T01:45:23Z ERROR cannot start service while terminating
-----
unit-postgresql-k8s-1: 01:53:34 ERROR unit.postgresql-k8s/1.juju-log Failed to restart patroni
Traceback (most recent call last):
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/./src/charm.py", line 1418, in _on_update_status
    container.restart(self._postgresql_service)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/ops/model.py", line 2399, in restart
    self._pebble.restart_services(service_names)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/ops/pebble.py", line 2219, in restart_services
    return self._services_action('restart', services, timeout, delay)
  File "/var/lib/juju/agents/unit-postgresql-k8s-1/charm/venv/ops/pebble.py", line 2244, in _services_action
    raise ChangeError(change.err, change)
ops.pebble.ChangeError: cannot perform the following tasks:
- Start service "postgresql" (cannot start service while terminating)
----- Logs from task 0 -----
2024-10-03T01:53:34Z INFO Service "postgresql" already stopping.
----- Logs from task 1 -----
2024-10-03T01:53:34Z ERROR cannot start service while terminating
-----
unit-postgresql-k8s-0: 02:01:19 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [a106a7] "unit-postgresql-k8s-0" cannot open api: cannot resolve "controller-service.controller-microk8s-localhost.svc.cluster.local": lookup controller-service.controller-microk8s-localhost.svc.cluster.local: i/o timeout
unit-postgresql-k8s-0: 02:01:26 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [a106a7] "unit-postgresql-k8s-0" cannot open api: cannot resolve "controller-service.controller-microk8s-localhost.svc.cluster.local": lookup controller-service.controller-microk8s-localhost.svc.cluster.local: i/o timeout
unit-postgresql-k8s-0: 02:01:34 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [a106a7] "unit-postgresql-k8s-0" cannot open api: try was stopped

[32mINFO    [0m pytest_operator.plugin:plugin.py:991 Forgetting model main...